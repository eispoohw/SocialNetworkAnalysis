{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\darin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\darin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\darin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\darin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "     sentiment                                               text\nid                                                               \n3204       sad  agree the poor in india are treated badly thei...\n1431       joy  if only i could have spent the with this cutie...\n654        joy  will nature conservation remain a priority in ...\n2530       sad  coronavirus disappearing in italy show this to...\n2296       sad  uk records lowest daily virus death toll since...\n...        ...                                                ...\n2579       sad  today at 02 30pm a 54 year old bangladeshi mal...\n3579     anger  corona virus i implore that you cease activity...\n221        joy  issa date once lockdown ends inshaallah (and c...\n2705       sad  the death toll due to covid 19 rose to 31 in j...\n2962       sad  the rates are become barrier for poor people t...\n\n[3090 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>text</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3204</th>\n      <td>sad</td>\n      <td>agree the poor in india are treated badly thei...</td>\n    </tr>\n    <tr>\n      <th>1431</th>\n      <td>joy</td>\n      <td>if only i could have spent the with this cutie...</td>\n    </tr>\n    <tr>\n      <th>654</th>\n      <td>joy</td>\n      <td>will nature conservation remain a priority in ...</td>\n    </tr>\n    <tr>\n      <th>2530</th>\n      <td>sad</td>\n      <td>coronavirus disappearing in italy show this to...</td>\n    </tr>\n    <tr>\n      <th>2296</th>\n      <td>sad</td>\n      <td>uk records lowest daily virus death toll since...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2579</th>\n      <td>sad</td>\n      <td>today at 02 30pm a 54 year old bangladeshi mal...</td>\n    </tr>\n    <tr>\n      <th>3579</th>\n      <td>anger</td>\n      <td>corona virus i implore that you cease activity...</td>\n    </tr>\n    <tr>\n      <th>221</th>\n      <td>joy</td>\n      <td>issa date once lockdown ends inshaallah (and c...</td>\n    </tr>\n    <tr>\n      <th>2705</th>\n      <td>sad</td>\n      <td>the death toll due to covid 19 rose to 31 in j...</td>\n    </tr>\n    <tr>\n      <th>2962</th>\n      <td>sad</td>\n      <td>the rates are become barrier for poor people t...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3090 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/finalSentimentdata2.csv')\n",
    "df = df.rename({'Unnamed: 0': 'id'}, axis=1).set_index('id')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "     sentiment                                               text\nid                                                               \n3204       sad  agree the poor in india are treated badly thei...\n1431       joy  if only i could have spent the with this cutie...\n654        joy  will nature conservation remain a priority in ...\n2530       sad  coronavirus disappearing in italy show this to...\n2296       sad  uk records lowest daily virus death toll since...\n...        ...                                                ...\n2194       joy  it was tough to see you go brother excellent 6...\n2579       sad  today at 02 30pm a 54 year old bangladeshi mal...\n221        joy  issa date once lockdown ends inshaallah (and c...\n2705       sad  the death toll due to covid 19 rose to 31 in j...\n2962       sad  the rates are become barrier for poor people t...\n\n[1522 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>text</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3204</th>\n      <td>sad</td>\n      <td>agree the poor in india are treated badly thei...</td>\n    </tr>\n    <tr>\n      <th>1431</th>\n      <td>joy</td>\n      <td>if only i could have spent the with this cutie...</td>\n    </tr>\n    <tr>\n      <th>654</th>\n      <td>joy</td>\n      <td>will nature conservation remain a priority in ...</td>\n    </tr>\n    <tr>\n      <th>2530</th>\n      <td>sad</td>\n      <td>coronavirus disappearing in italy show this to...</td>\n    </tr>\n    <tr>\n      <th>2296</th>\n      <td>sad</td>\n      <td>uk records lowest daily virus death toll since...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2194</th>\n      <td>joy</td>\n      <td>it was tough to see you go brother excellent 6...</td>\n    </tr>\n    <tr>\n      <th>2579</th>\n      <td>sad</td>\n      <td>today at 02 30pm a 54 year old bangladeshi mal...</td>\n    </tr>\n    <tr>\n      <th>221</th>\n      <td>joy</td>\n      <td>issa date once lockdown ends inshaallah (and c...</td>\n    </tr>\n    <tr>\n      <th>2705</th>\n      <td>sad</td>\n      <td>the death toll due to covid 19 rose to 31 in j...</td>\n    </tr>\n    <tr>\n      <th>2962</th>\n      <td>sad</td>\n      <td>the rates are become barrier for poor people t...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1522 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sadjoy = df[df['sentiment'].isin(['sad', 'joy'])]\n",
    "sadjoy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stopwords = set(stopwords.words('english'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def preprocessor(row: str):\n",
    "    row = re.sub(\"[@#][A-Za-z0-9]+\", \"\", row)\n",
    "    row = re.sub(f\"[{string.punctuation}]\", \"\", row)\n",
    "    row = row.lower()\n",
    "    row = [lemmatizer.lemmatize(word) for word in word_tokenize(row) if lemmatizer.lemmatize(word) not in stopwords]\n",
    "    return \" \".join(row)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sadjoy['text'], sadjoy['sentiment'])\n",
    "\n",
    "X_train = X_train.apply(preprocessor)\n",
    "X_test = X_test.apply(preprocessor)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.824\n"
     ]
    },
    {
     "data": {
      "text/plain": "(1, 1)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vect__ngram_range': ((1, 1), (1, 2), (1, 3), (2, 3), (2, 2), (3, 3)),\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "bs = grid_search.best_estimator_.get_params()['vect__ngram_range']\n",
    "bs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         joy       0.78      0.82      0.80       167\n",
      "         sad       0.85      0.82      0.84       214\n",
      "\n",
      "    accuracy                           0.82       381\n",
      "   macro avg       0.82      0.82      0.82       381\n",
      "weighted avg       0.82      0.82      0.82       381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=bs)\n",
    "v_X_train = vectorizer.fit_transform(X_train)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(v_X_train, y_train)\n",
    "\n",
    "pred = clf.predict(vectorizer.transform(X_test))\n",
    "print(classification_report(pred, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vect__ngram_range': ((1, 1), (1, 2), (1, 3), (2, 3)),\n",
    "    'vect__max_df': (0.25, 0.5, 0.75, 1.0),\n",
    "    'vect__min_df': (0.01, 0.02, 0.03, 0.04),\n",
    "    'vect__max_features': (400, 500, 600, 700, 800, 900, 1000, 1141),\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grid_search.best_estimator_.get_params()['vect']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_df=0.25, max_features=400, min_df=0.01)\n",
    "v_X_train = vectorizer.fit_transform(X_train)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(v_X_train, y_train)\n",
    "\n",
    "pred = clf.predict(vectorizer.transform(X_test))\n",
    "print(classification_report(pred, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "newdf = pd.read_csv('data/covid19_tweets.csv')\n",
    "newdf['text'] = newdf['text'].apply(preprocessor)\n",
    "newdf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred = clf.predict(vectorizer.transform(newdf))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sad, joy = 0, 0\n",
    "for elem in pred:\n",
    "    if elem == 'sad':\n",
    "        sad += 1\n",
    "    else:\n",
    "        joy += 1\n",
    "\n",
    "print('joy:', joy, f'\\t{joy / (joy + sad) * 100} %')\n",
    "print('sad:', sad, f'\\t{sad / (joy + sad) * 100} %')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob import Blobber\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "\n",
    "nltk.download('movie_reviews', quiet=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tb = Blobber(analyzer=NaiveBayesAnalyzer())\n",
    "\n",
    "res = newdf['text'].apply(lambda x: tb(x).sentiment.classification)\n",
    "res.value_counts(normalize=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}