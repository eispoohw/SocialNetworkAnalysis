{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\darin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\darin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\darin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\darin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "import pyLDAvis as pyLDAvis\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from gensim.models import LdaMulticore, CoherenceModel, LdaModel\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stopwords = set(stopwords.words('english'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def preprocessor(row: str):\n",
    "    row = re.sub(\"[@#][A-Za-z0-9]+\", \"\", row)\n",
    "    row = re.sub(f\"[{string.punctuation}]\", \"\", row)\n",
    "    row = row.lower()\n",
    "    row = [lemmatizer.lemmatize(word) for word in word_tokenize(row) if lemmatizer.lemmatize(word) not in stopwords]\n",
    "    return \" \".join(row)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                     text\n0       smelled scent hand sanitizers today someone pa...\n1       hey wouldnt made sense player pay respect a… h...\n2       trump never claimed wa hoax claim effort to… h...\n3       one gift ha give appreciation simple thing alw...\n4       25 july medium bulletin novel … httpstcomn0eec...\n...                                                   ...\n179103  thanks nominating challenge nominate … httpstc...\n179104          2020 year insanity lol httpstcoy48np0yzgn\n179105  powerful painting juan lucena tribute grandpar...\n179106  1200 student test positive major university ab...\n179107        stop see stop ent sabc1… httpstcoreg8pwzon7\n\n[179108 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>smelled scent hand sanitizers today someone pa...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>hey wouldnt made sense player pay respect a… h...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>trump never claimed wa hoax claim effort to… h...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>one gift ha give appreciation simple thing alw...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>25 july medium bulletin novel … httpstcomn0eec...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>179103</th>\n      <td>thanks nominating challenge nominate … httpstc...</td>\n    </tr>\n    <tr>\n      <th>179104</th>\n      <td>2020 year insanity lol httpstcoy48np0yzgn</td>\n    </tr>\n    <tr>\n      <th>179105</th>\n      <td>powerful painting juan lucena tribute grandpar...</td>\n    </tr>\n    <tr>\n      <th>179106</th>\n      <td>1200 student test positive major university ab...</td>\n    </tr>\n    <tr>\n      <th>179107</th>\n      <td>stop see stop ent sabc1… httpstcoreg8pwzon7</td>\n    </tr>\n  </tbody>\n</table>\n<p>179108 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/covid19_tweets.csv')\n",
    "\n",
    "df = df[['text']]\n",
    "df['text'] = df['text'].apply(preprocessor)\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "docs = df['text'].apply(lambda row: row.split(' ')).tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(docs)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 8/19 [06:49<09:39, 52.70s/it]"
     ]
    }
   ],
   "source": [
    "coherence_values = []\n",
    "\n",
    "for t in tqdm(range(1, 20)):\n",
    "    model = LdaMulticore(corpus=corpus, id2word=dictionary, num_topics=t, random_state=200, workers=4)\n",
    "    coherence_model = CoherenceModel(model=model, texts=docs, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_values.append(coherence_model.get_coherence())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot([_ for _ in range(1, 20)], coherence_values)\n",
    "plt.xticks([_ for _ in range(1, 20)])\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = LdaMulticore(corpus=corpus, id2word=dictionary, num_topics=2, workers=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vis = gensimvis.prepare(model, corpus, dictionary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "smpl = df.sample(5000)\n",
    "smpl"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch, os, re, pandas as pd, json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DataCollatorForLanguageModeling, DataCollatorWithPadding, GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, AutoConfig\n",
    "from datasets import Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "device = torch.device(dev)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "base_model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "base_model.num_parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "base_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "bos = '<|endoftext|>'\n",
    "eos = '<|EOS|>'\n",
    "pad = '<|pad|>'\n",
    "\n",
    "special_tokens_dict = {'eos_token': eos, 'bos_token': bos, 'pad_token': pad}\n",
    "num_added_toks = base_tokenizer.add_special_tokens(special_tokens_dict)\n",
    "config = AutoConfig.from_pretrained('gpt2',\n",
    "                                    bos_token_id=base_tokenizer.bos_token_id,\n",
    "                                    eos_token_id=base_tokenizer.eos_token_id,\n",
    "                                    pad_token_id=base_tokenizer.pad_token_id,\n",
    "                                    output_hidden_states=False)\n",
    "base_model = GPT2LMHeadModel.from_pretrained('gpt2', config=config)\n",
    "base_model.resize_token_embeddings(len(base_tokenizer))\n",
    "\n",
    "smpl['text'] = bos + ' ' + smpl['text'] + ' ' + eos\n",
    "df_train, df_val = train_test_split(smpl, train_size=0.8)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(df_train[['text']])\n",
    "val_dataset = Dataset.from_pandas(df_val[['text']])\n",
    "\n",
    "\n",
    "def tokenize_function(df, base_tokenizer=base_tokenizer):\n",
    "    return base_tokenizer(df['text'], padding=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenized_train_dataset = train_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    num_proc=5,\n",
    "    remove_columns=['text'],\n",
    ")\n",
    "tokenized_val_dataset = val_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    num_proc=5,\n",
    "    remove_columns=['text'],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "model_path = './model_tw'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=model_path,\n",
    "  num_train_epochs=6,\n",
    "  per_device_train_batch_size=32,\n",
    "  per_device_eval_batch_size=16,\n",
    "  warmup_steps=200,\n",
    "  weight_decay=0.01,\n",
    "  logging_dir=model_path,\n",
    "  prediction_loss_only=True,\n",
    "  save_steps=10000\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "  tokenizer=base_tokenizer,\n",
    "  mlm=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "  model=base_model,\n",
    "  args=training_args,\n",
    "  data_collator=data_collator,\n",
    "  train_dataset=tokenized_train_dataset,\n",
    "  eval_dataset=tokenized_val_dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.save_model()\n",
    "base_tokenizer.save_pretrained(model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tweets_model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "tweets_tokenizer = GPT2Tokenizer.from_pretrained(model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_n_text_samples(model, tokenizer, input_text, device, n_samples = 5):\n",
    "    text_ids = tokenizer.encode(input_text, return_tensors = 'pt')\n",
    "    text_ids = text_ids.to(device)\n",
    "    model = model.to(device)\n",
    "\n",
    "    generated_text_samples = model.generate(\n",
    "        text_ids,\n",
    "        max_length= 100,\n",
    "        num_return_sequences= n_samples,\n",
    "        no_repeat_ngram_size= 2,\n",
    "        repetition_penalty= 1.5,\n",
    "        top_p= 0.92,\n",
    "        temperature= .85,\n",
    "        do_sample= True,\n",
    "        top_k= 125,\n",
    "        early_stopping= True\n",
    "    )\n",
    "    gen_text = []\n",
    "    for t in generated_text_samples:\n",
    "        text = tokenizer.decode(t, skip_special_tokens=True)\n",
    "        gen_text.append(text)\n",
    "\n",
    "        return gen_text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_text = 'covid'\n",
    "generated_tweet = generate_n_text_samples(tweets_model, tweets_tokenizer, input_text, device)\n",
    "\n",
    "generated_tweet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}